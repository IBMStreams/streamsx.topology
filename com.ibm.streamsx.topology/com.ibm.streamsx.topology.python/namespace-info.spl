/*
# Licensed Materials - Property of IBM
# Copyright IBM Corp. 2015  
 */

/**

Alpha support for Python in IBM Streams.

This is an **alpha version** of `com.ibm.streamsx.topology` allows
use of Python in IBM Streams applications.

# Python Support

+ Decorating Python Functions as SPL Operators
SPL operators that call a Python function are created by
decorators provided by this toolkit.

`bin/spl-python-extract.py` is a Python script that creates SPL operators from
Python functions contained in modules in a toolkit.
The resulting operators embed the Python runtime to
allow stream processing using Python.

To create SPL operators from Python functions one or more Python
modules are created in the `opt/python/streams` directory
of an SPL toolkit.

Each module must import the `streamsx.spl`
package which is located in the `opt/packages` directory of this toolkit.
It contains the decorators use to create SPL operators from Python functions.
The module must also define a function `splNamespace` that returns a string
containing the SPL namespace the operators for that module will be placed in.

For example:


    # Import the SPL decorators
    from streamsx.spl import spl

    # Defines the SPL namespace for any functions in this module
    # Multiple modules can map to the same namespace
    def splNamespace():
       return "com.ibm.streamsx.topology.pysamples.mail"

Any Python docstring for the function is copied into the SPL operator's description field in its operator model, providing a description for IDE developers using the toolkit.

Functions in the modules that are not decorated, decorated with `@spl.ignore` or start with `spl` are ignored and will not result in any SPL operator.

++ Conversion between SPL and Python tuples.
SPL attributes map to Python tuples by position.
# SPL Tuple passed into a Python function
When an SPL tuple is passed into a Python function through its SPL operator
its attributes are passed by position. The first attribute is
the first positional parameter in the Python function. For example:
    # SPL input schema: tuple<int32 id, float64 reading>
    ＠spl.sink
    def myfunc(a,b):
      # a is set to: id
      # b is set to: reading

If more SPL attributes exist than specified parameters then the additional attributes are ignored.

A Python variable argument can be used to capture all of the remaining attributes, for example:
    # SPL input schema: tuple<int32 id, float64 reading, float lat, float lon>
    ＠spl.sink
    def myvarargfunc(a, *values)
      # a is set to: id
      # values is set to the values of: reading, lat, lon

# Python function return conversion to SPL Tuples
A Python function must return `None`, a Python tuple or a list of Python tuples.
When `None` is return then no tuple will be submitted to the operator's output port. When a single tuple is returned is is converted to an SPL tuple and submitted to the output port. When a list of tuples is returned, each tuple is converted to a tuple and submitted to the output port, in order of the list starting with the first tuple (position 0).

The values of a Python tuple are assigned to an output SPL tuple by position, so the first value in the Python tuple is assigned to the first attribute in the SPL tuple.

    # SPL output schema: tuple<int32 x, float64 y, float32 z>
    ＠spl.pipe
    def myfunc(a,b):
       return a,b,a+b

    # The SPL output will be:
    # x is set to: a
    # y is set to: b 
    # z is set to: a+b

When a returned tuple has less values than attributes in the SPL output schema the attributes not set by the Python function will be set to their SPL default or copied from the input tuple, depending on the operator type.

When a returned tuple has more values than attributes in the SPL output schema then the additional values are ignored.

++ \@spl.pipe
Decorator to create a pipe SPL operator.
When a Python function is decorated with `@spl.pipe`
a pipe SPL operator is created with a single input port
and single output port.  For each input tuple the function is called,
and its return value is used to submit zero or more tuples on the output port. 

When the function returns a tuple containing less values than attributes
in the SPL output schema then the remaining attributes are copied from
the input tuple if a matching attribute is found, otherwise they are set
to the SPL default value.

# Examples

Simple `Noop` pipe operator that passes the input SPL tuple onto its output using a variable argument.

    ＠spl.pipe
    def Noop(*tuple):
      "Pass the tuple along without any change"
      return tuple

Simple filter, note that no return statement is equivalent to returning `None`:
    ＠spl.pipe
    def SimpleFilter(a,b):
      "Filter tuples only allowing output if the first attribute is less than the second. Returns the sum of the first two attributes."
      if (a < b):
         return a+b,

Demonstration of returning multiple tuples as a list.
    ＠spl.pipe
    def ReturnList(a,b,c):
      "Demonstrate returning a list of values, each value is submitted as an SPL tuple" 
      return [(a+1,b+1,c+1),(a+2,b+2,c+2),(a+3,b+3,c+3),(a+4,b+4,c+4)]


++ \@spl.sink
Decorator to create a sink SPL operator.
If the Python function is decorated with `@spl.sink`
then the operator is a sink operator, with a single
input port and no output ports.
For each input tuple the function is called.

# Examples

Operator to send an e-mail for each tuple using the local SMTP server.

    import sys
    import smtplib
    
    # Import the SPL decorators
    from streamsx.spl import spl
    
    server = smtplib.SMTP('localhost')

    def splNamespace():
        return "com.ibm.streamsx.topology.pysamples.mail"

    # Decorate this function as a sink operator
    # This means the operator will have a single
    # input port and no output ports. The SPL tuple
    # is passed in as described in spl_samples.py.
    # The function must return None, typically by
    # not having any return statement.
    ＠spl.sink
    def simplesendmail(from_addr, to_addrs, msg):
        "Send a simple email"
        server.sendmail(from_addr, to_addrs, msg)

++ \@spl.ignore
Decorator to ignore a Python function.
If the Python function is decorated with `@spl.ignore`
then function is ignored by `spl-python-extract.py`.

++ Extracting SPL operators from decorated Python functions

To create operators in a toolkit, execute `python3 spl-python-extract.py -i toolkit-directory`. Any Python module in the toolkit's `opt/python/streams` directory will have its functions converted to SPL operators.

These directories in a toolkit are automatically added to the Python search path during execution of an operator.
 * `opt/python/streams` - Contains modules that define Python functions that will be created as SPL operators
 * `opt/python/packages` - Root directory for Python [https://docs.python.org/3.4/tutorial/modules.html#packages|packages] hierarchy.
 * `opt/python/modules` - Arbitrary [https://docs.python.org/3.4/tutorial/modules.html#modules|modules], not defined as a packages.

A single Python embedded runtime is used by an SPL processing element (PE), thus when multiple operators
implemented in python are fused into the same PE they share the same runtime. The library and include
paths to the Python runtime are set from the version of Python used to execute `spl-python-extract.py`.

The toolkit has no dependency on this toolkit (`com.ibm.streamsx.topology`) once `spl-python-extract.py` has been executed.

The sample SPL toolkit `samples/python/com.ibm.streamsx.topology.pysamples` contains `opt/python/streams/spl_samples.py` for
examples of how data is passed into and out of Python from SPL,
using positional arguments.

E.g.

python3 $HOME/toolkits/com.ibm.streamsx.topology/bin/spl-python-extract.py -i samples/python/com.ibm.streamsx.topology.pysamples

++ Sample toolkit

A toolkit with a number of decorated Python functions and SPL applications that invoke them is supplied under `samples/python/com.ibm.streamsx.topology.pysamples`.

+ Python Application API
Develop IBM Streams applications with Python.

**Alpha version, basic functionality**

This is intended as a preview of the intended direction, functionality
is limited.

# Overview

A functional api to develop streaming applications for IBM Streams
using Python. Streams are defined, transformed and sinked (terminated)
using Python functions. The return of a function determines the
content of the stream. Tuples on a stream are Python objects,
a stream may contain different types of objects.

# Assumptions

* CPython 3.5 is assumed
* Limited testing has been performed with CPython 3.5.1
* Python is installed in the default location (`/usr/local`)

# Sample HelloWorld Application

Example code that builds and then submits a Hello World topology.

    import mymodule;
    from streamsx.topology.topology import *
    import streamsx.topology.context

    topo = Topology("HelloWorld")
    hw = topo.source(mymodule.hello_world)
    hw.sink(print)
    streamsx.topology.context.submit("STANDALONE", topo.graph)

The `source` function is passed a callable that returns an `Iterable`, in
this case `mymodule.hello_world`.


    def hello_world() :
        return ["Hello", "World!"]

The callable will be called when the application starts, and the SPL runtime will create an iterator from the returned value. Then each value returned from the iterator will be sent on the stream.

The `sink` function is passed a callable that will be called for each tuple
on the stream, in this case the builtin `print` function.

The callable input must be one of the following:
  * the name of a built-in function
  * the name of a function defined at the top level of a module that takes no arguments
  * an instance of a callable class defined at the top level of a module that implements the method `__call__` and is picklable
  
Using a callable class allows state information such as user-defined parameters to be stored during class 
initialization and utilized when the instance is called.

The modules containing the callables are copied into the Streams Application Bundle (sab file).

Limitations on callable inputs to operations:
* Callables must be defined in a module file.
* Callables must not be dynamically created nor anonymous.
* Callables must not be defined in the `__main__` module.  They must be defined in a separate module.
* Importing modules that contain user-defined functions with importlib is unsupported.  The PYTHONPATH or sys.path must contain the directory where modules to import are located.
* Importing modules that contain user-defined functions from zip/egg/wheel files is unsupported.

To avoid name conflicts, do not create modules with the same name as 
* `streamsx` which is used by the Python Application API
* built-in or standard library module names

# Streams functions 

* `source(self, func)` function on `Topology`

  Fetches information from an external system and presents that information as a stream.
  Takes a zero-argument callable that returns an iterable of tuples.
  Each tuple that is not None from the iterator returned
  from iter(func()) is present on the returned stream.

  param `func`: A zero-argument callable that returns an iterable of tuples.
  A tuple is represented as a Python object that must be picklable.

  return: A stream whose tuples are the result of the output obtained by invoking the provided callable.

* `sink(self, func)` function on `Stream`

  Sends information as a stream to an external system.
  Takes a user provided callable that does not return a value.

  param `func`: A callable that takes a single parameter for the tuple and returns None.
  The callable is invoked for each incoming tuple.  
  
  return: None
        
* `filter(self, func)` function on `Stream`

  Filters tuples from a stream using the supplied callable `func`.
  For each tuple on the stream the callable is called passing
  the tuple, if the callable return evalulates to true the
  tuple will be present on the returned stream, otherwise
  the tuple is filtered out.
  
  param `func`: A callable that takes a single parameter for the tuple, and returns True or False.
  If True, the tuple is included on the returned stream.  If False, the tuple is filtered out.
  The callable is invoked for each incoming tuple.
  
  return: A stream containing tuples that have not been filtered out.
  
* `transform(self, func)` function on `Stream`

  Transforms each tuple from this stream into 0 or 1 tuples using the supplied callable `func`.
  For each tuple on this stream, the returned stream will contain a tuple
  that is the result of the callable when the return is not None.
  If the callable returns None then no tuple is submitted to the returned 
  stream.
 
  param `func`: A callable that takes a single parameter for the tuple, and returns a tuple or None.
  The callable is invoked for each incoming tuple.
 
  return: A stream containing transformed tuples.
  
* `multi_transform(self, func)` function on `Stream`

  Transforms each tuple from this stream into 0 or more tuples using the supplied callable `func`. 
  For each tuple on this stream, the returned stream will contain all non-None tuples from
  the iterable.
  Tuples will be added to the returned stream in the order the iterable
  returns them.
  If the return is None or an empty iterable then no tuples are added to
  the returned stream.

  param `func`: A callable that takes a single parameter for the tuple, and returns an iterable of tuples or None.
  The callable must return an iterable or None, otherwise a TypeError is raised.
  The callable is invoked for each incoming tuple.

  return: A stream containing transformed tuples.
  
* `isolate` function on `Stream`

  Guarantees that the upstream operation will run in a separate process from the downstream operation when 
  the application is executed in distributed mode.
  
* `low_latency` and `end_low_latency` functions on `Stream`

  The function is guaranteed to run in the same process as the
  upstream Stream function. All streams that are created from the returned stream 
  are also guaranteed to run in the same process until end_low_latency() 
  is called.

* `union` function on `Stream`

  The Union operator merges the outputs of the streams in the set into a single stream.

*  `parallel` and `end_parallel` functions on `Stream`

  Marks operator as parallel output with width specified



# Sample Transform Application

Example code that builds and then submits a simple topology.

    from streamsx.topology.topology import Topology
    import streamsx.topology.context
    import transform_sample_functions;

    topo = Topology("transform_sample")
    source = topo.source(transform_sample_functions.int_strings_transform)
    i1 = source.transform(transform_sample_functions.string_to_int)
    i2 = i1.transform(transform_sample_functions.AddNum(17))
    i2.sink(print)
    streamsx.topology.context.submit("STANDALONE", topo.graph)

The `source` function is passed a function that returns an `Iterable`, in
this case `transform_sample_functions.int_strings_transform`.

    def int_strings_transform():
        return ["325", "457", "9325"]

The first `transform` function is passed a function that returns an integer
converted from the string object, in this case `transform_sample_functions.string_to_int`.

    def string_to_int(t):
        return int(t)

The second `transform` function is passed an instance of a callable class that adds 17 to the integer,
in this case `transform_sample_functions.AddNum(17)`.

    class AddNum:
        def __init__(self, increment):
            self.increment = increment  
        def __call__(self, tuple):
            return tuple + self.increment

When building the topology the directory `com.ibm.streamsx.topology/opt/python/packages` must be in `$PYTHONPATH`.

The sample `transform_sample.py` can be found under `samples/python/topology/simple`.
After setting the PYTHONPATH, the sample can be executed using `python3 transform_sample.py`.
Sample output:
    342
    474
    9342

Only submission using the STANDALONE or BUNDLE context type are supported.
* The STANDALONE context type converts the application to an SPL graph, compiles it and executes it as an IBM Streams standalone application.  The standalone execution is spawned as a separate process.
* The BUNDLE context type converts the application to an SPL graph and compiles it, producing a SPL application bundle (.sab file).  The application is executed separately by submitting the bundle to an IBM Streams instance as a distributed application.  A bundle can be submitted to an IBM Streams instance using `streamtool submitjob`, the IBM Streams Console, or IBM Streams JMX API.

Limited testing has been performed to build an application using BUNDLE.

# Future Items

Future items that need to be supported

* `parallel()` function on `Stream` utilizing hashed distribution
* DISTRIBUTED submission
* lambda functions
* dynamic functions
* IBM Streams application features, such as UDP, windowing etc.
* ...

*/

namespace com.ibm.streamsx.topology.python;

